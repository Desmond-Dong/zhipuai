{
  "config": {
    "step": {
      "user": {
        "data": {
          "name": "Custom Name",
          "api_key": "API Key"
        },
        "description": "Get the key: [Click link](https://open.bigmodel.cn/console/modelft/dataset)"
      }
    },
    "error": {
      "cannot_connect": "Unable to connect to the service",
      "invalid_auth": "Invalid authentication",
      "unknown": "Configuration saved, no further action needed",
      "cooldown_too_small": "Cooldown value {value} is too small, please set a value greater than or equal to 0!",
      "cooldown_too_large": "Cooldown value {value} is too large, please set a value less than or equal to 10!",
      "invalid_option": "Invalid option value"
    },
    "abort": {
      "single_instance_allowed": "Already configured, only one configuration entry is allowed."
    }
  },
  "options": {
    "step": {
      "init": {
        "data": {
          "prompt": "Command",
          "chat_model": "Chat Model",
          "max_tokens": "Maximum number of tokens returned in response",
          "temperature": "Temperature",
          "top_p": "Top P",
          "llm_hass_api": "Options",
          "recommended": "Recommended model settings (The default is the free general-purpose 128K model. If needed, other paid models can be selected, and the actual cost is not high.)",
          "max_history_messages": "Maximum number of history messages",
          "max_tool_iterations": "Maximum number of tool calls",
          "cooldown_period": "Cooldown time (seconds)"
        },
        "data_description": {
          "prompt": "Instructions on how the LLM should respond. This can be a template.",
          "chat_model": "Fill in the chat model to use",
          "max_tokens": "Set the maximum number of tokens returned in response",
          "temperature": "Controls output randomness (0-2)",
          "top_p": "Controls output diversity (0-1)",
          "llm_hass_api": "Home Assistant LLM API",
          "recommended": "Use recommended model settings",
          "max_history_messages": "Set the maximum number of history messages to retain. Purpose: Controls memory functionality to ensure smooth contextual conversation. For home devices, itâ€™s best to set within 5 times to handle failed requests. For other daily conversations, set a threshold above 10.",
          "max_tool_iterations": "Set the maximum number of tool calls in a single conversation. Purpose: Sets a call request threshold to avoid No system deadlock due to errors, especially designed for low-performance hosts. Recommended: 10-20 times.",
          "cooldown_period": "Set the minimum interval time between two conversation requests (0-10 seconds). Purpose: Requests will be delayed before being sent. Recommended: within 3 seconds. Ensures the request isn't rejected due to rate limits."
        }
      }
    }
  },
  "exceptions": {
    "invalid_config_entry": {
      "message": "The provided configuration entry is invalid. Received: {config_entry}"
    }
  }
}
