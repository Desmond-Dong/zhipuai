{
  "config": {
    "step": {
      "user": {
        "data": {
          "name": "custom name",
          "api_key": "API key"
        },
        "description": "Get the key: [Click the link](https://open.bigmodel.cn/console/modelft/dataset)"
      },
      "reauth_confirm": {
        "title": "Re-validate Wisdom Spectrum AI",
        "description": "Your Zhipu AI API key has expired, please enter a new API key",
        "data": {
          "api_key": "API key"
        }
      },
      "reconfigure_confirm": {
        "title": "Reconfigure Zhipu AI",
        "description": "Please enter new configuration information",
        "data": {
          "api_key": "API key"
        }
      }
    },
    "error": {
      "cannot_connect": "Unable to connect to service",
      "invalid_auth": "API key error",
      "unknown": "unknown error",
      "cooldown_too_small": "The cooling time value {value} is too small, please set a value greater than or equal to 0!",
      "cooldown_too_large": "The cooling time value {value} is too large, please set a value less than or equal to 10!",
      "model_not_found": "The specified model could not be found"
    },
    "abort": {
      "already_configured": "The device has been configured",
      "reauth_successful": "Re-authentication successful",
      "reconfigure_successful": "Reconfiguration successful"
    }
  },
  "options": {
    "step": {
      "init": {
        "data": {
          "chat_model": "chat model",
          "temperature": "temperature",
          "max_tokens": "Maximum number of tokens",
          "max_history_messages": "Maximum number of historical messages",
          "top_p": "Top P",
          "prompt": "prompt word template",
          "max_tool_iterations": "Maximum number of tool iterations",
          "cooldown_period": "Cooling time (seconds)",
          "llm_hass_api": "Home Assistant LLM API",
          "recommended": "Use recommended model settings"
        },
        "data_description": {
          "prompt": "Indicates how LLM should respond. This can be a template.",
          "chat_model": "Please select the chat model you want to use (the free universal 128K model is selected by default. If you need a better experience, you can choose to support other paid models. The actual cost is not high. Please check the official website billing standards for details)",
          "max_tokens": "Set the maximum number of tokens returned in the response",
          "temperature": "Controls the randomness of the output (0-2)",
          "top_p": "Control output diversity (0-1)",
          "llm_hass_api": "Home Assistant LLM API",
          "recommended": "Use recommended model settings",
          "max_history_messages": "Set the maximum number of historical messages to be retained. Function: Controls the memory function of input content. The memory function can ensure smooth conversation in the context. Generally, it is best to control home devices within 5 times, which is effective for requests that cannot be made smoothly. For other daily conversations, the threshold can be set to more than 10 times.",
          "max_tool_iterations": "Set the maximum number of tool calls in a single conversation. Its function is to set the call threshold for system LLM call requests. If there is an error, it can ensure that the system is not stuck. Especially for the design of various small hosts with weak performance. It is recommended to set it 20-30 times.",
          "cooldown_period": "Set the minimum interval between two conversation requests (0-10 seconds). Effect: The request will be delayed for a period of time before being sent. It is recommended to set it within 3 seconds. It is guaranteed that the content sending request fails due to rate factors."
        }
      }
    }
  },
  "exceptions": {
    "invalid_config_entry": {
      "message": "The provided configuration entry is invalid. What you get is {config_entry}"
    }
  }
}