{
  "config": {
    "step": {
      "user": {
        "data": {
          "name": "Custom Name",
          "api_key": "API Key"
        },
        "description": "Get your key: [Click the link](https://open.bigmodel.cn/console/modelft/dataset)"
      },
      "reauth_confirm": {
        "title": "Reauthenticate ZhiPu AI",
        "description": "Your ZhiPu AI API key has expired. Please enter a new API key.",
        "data": {
          "api_key": "API Key"
        }
      },
      "reconfigure_confirm": {
        "title": "Reconfigure ZhiPu AI",
        "description": "Please enter the new configuration information.",
        "data": {
          "api_key": "API Key"
        }
      }
    },
    "error": {
      "cannot_connect": "Unable to connect to the service",
      "invalid_auth": "Invalid authentication",
      "unknown": "Configuration saved, no need for a second entry.",
      "cooldown_too_small": "Cooldown period value {value} is too small. Please set it to a value greater than or equal to 0!",
      "cooldown_too_large": "Cooldown period value {value} is too large. Please set it to a value less than or equal to 10!",
      "invalid_option": "Invalid option value"
    },
    "abort": {
      "single_instance_allowed": "Already configured; only one configuration entry is allowed.",
      "reauth_successful": "Reauthentication successful",
      "reconfigure_successful": "Reconfiguration successful"
    }
  },
  "options": {
    "step": {
      "init": {
        "data": {
          "prompt": "Instruction",
          "chat_model": "Chat Model",
          "max_tokens": "Maximum tokens to return in response",
          "temperature": "Temperature",
          "top_p": "Top P",
          "llm_hass_api": "Option",
          "recommended": "Recommended model settings",
          "max_history_messages": "Maximum number of history messages",
          "max_tool_iterations": "Maximum tool invocation count",
          "cooldown_period": "Cooldown time (seconds)"
        },
        "data_description": {
          "prompt": "Instructions on how the LLM should respond. This can be a template.",
          "chat_model": "Please select the chat model to use (the default free general 128K model is pre-selected; if you require a better experience, you can choose to support other paid models, which are not very expensive. Please check the official website for billing standards.)",
          "max_tokens": "Set the maximum number of tokens to return in the response.",
          "temperature": "Controls the randomness of the output (0-2)",
          "top_p": "Controls the diversity of the output (0-1)",
          "llm_hass_api": "Home Assistant LLM API",
          "recommended": "Use recommended model settings",
          "max_history_messages": "Set the maximum number of history messages to retain. This controls the memory function of the input content, ensuring smooth dialogue. Typically, it is best to keep it within 5 for home device controls, effectively addressing requests that cannot be smoothly processed. For other daily conversations, a threshold of more than 10 can be set.",
          "max_tool_iterations": "Set the maximum number of tool invocations in a single dialogue. This controls the threshold for requests to the system LLM, ensuring that the system does not get stuck in case of errors, especially designed for various low-performance small hosts. It is recommended to set this to 20-30 times.",
          "cooldown_period": "Set the minimum interval time between two dialogue requests (0-10 seconds). This allows requests to wait for a period before sending, recommended to set within 3 seconds to prevent failures due to rate factors."
        }
      }
    }
  },
  "exceptions": {
    "invalid_config_entry": {
      "message": "The provided configuration entry is invalid. Received: {config_entry}"
    }
  }
}
