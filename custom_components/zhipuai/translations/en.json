{
  "title": "Wisdom and clear words",
  "config": {
    "step": {
      "user": {
        "data": {
          "name": "Custom name",
          "api_key": "API Key"
        },
        "description": "Get the key: [Click the link](https://www.bigmodel.cn/invite?icode=9niOGcfvBKiiCpCLI4tgtX3uFJ1nZ0jLLgipQkYjpcA%3D)"
      },
      "reauth_confirm": {
        "title": "Re-verification Zhipu AI",
        "description": "Your Zhipu AI API key has expired. Please enter a new API key",
        "data": {
          "api_key": "API Key"
        }
      },
      "reconfigure_confirm": {
        "title": "Reconfiguration Zhipu AI",
        "description": "Please enter new configuration information",
        "data": {
          "api_key": "API Key"
        }
      }
    },
    "error": {
      "cannot_connect": "Unable to connect to the service",
      "invalid_auth": "API key error",
      "unknown": "Unknown error",
      "model_not_found": "The specified model cannot be found",
      "invalid_api_key": "API Key format error"
    },
    "abort": {
      "already_configured": "The device has been configured",
      "reauth_successful": "Re-certification successful",
      "reconfigure_successful": "Reconfiguration successfully"
    }
  },
  "options": {
    "step": {
      "init": {
        "data": {
          "chat_model": "Chat Model",
          "temperature": "temperature",
          "max_tokens": "Maximum number of tiles",
          "max_history_messages": "Maximum historical news",
          "top_p": "Top P",
          "prompt": "Prompt word template",
          "max_tool_iterations": "Maximum number of tool iterations",
          "request_timeout": "Request timeout (seconds)",
          "filter_markdown": "Markdown format filtering",
          "llm_hass_api": "Home Assistant LLM API",
          "recommended": "Settings with the recommended model",
          "web_search": "Internet analysis search",
          "history_analysis": "Entity historical data analysis",
          "presence_penalty": "Topic freshness",
          "frequency_penalty": "Repetition penalty",
          "stop_sequences": "Stop order",
          "tool_choice": "Tool usage mode",
          "notify_service": "Notification Service"
        },
        "data_description": {
          "prompt": "Indicates how the LLM should respond. This can be a template.",
          "chat_model": "Please select the chat model you want to use. By default, please choose the free universal 128K model. If you need a better experience, you can choose to support other paid models. The actual cost is not high. Please check the billing standards on the official website for details.",
          "max_tokens": "Sets the maximum word limit for AI response. Suggested values: dialogue 200-500, summary 800-1500, creation 2000-3000. The larger the value, the more detailed the response. The higher the fee for paid models such as Plus, because it is a reply length set by family communication to 250 words.",
          "temperature": "Control the creativity of AI answers (0-2). 0 is the most conservative and rigorous, 1 is balanced and divergent, and 2 is the most creative. Suggestions: Instruction execution uses 0-0.3, daily conversations 0.5-0.7, creative divergence 0.8-1, default is the intermediate value of regular conversations",
          "top_p": "Control the novelty of the answer (0-1). The greater the value, the more novel the word selection is, but it may not be stable enough. Suggestions: Use 0.1-0.3 for accurate tasks, 0.5-0.7 for regular conversations, and 0.8-1 for creative tasks, which defaults to the intermediate value of regular conversations.",
          "notify_service": "Specifies the service to use when sending notifications. By default, select Global Notifications to use Home Assistant's persistent notifications, or select a specific notification service. Give an example to AI verbal: Notify that tomorrow is her daughter’s birthday wish.",
          "llm_hass_api": "Turn on the LLM API",
          "recommended": "New! Optional advanced features",
          "max_history_messages": "Sets the maximum number of historical messages to keep. Function: Control the memory function of the input content. The memory function can ensure smooth context dialogue. Generally, it is best to control the home equipment within 5 times. The request cannot be smoothly effective. Other daily conversations can be set to a threshold of more than 10 times.",
          "max_tool_iterations": "Sets the maximum number of tool calls in a single conversation. Its function is to set a call threshold for system LLM call requests. If an error occurs, it can ensure that the system will not be stuck. Especially for designs of various small hosts with weaker performance, it is recommended to set it 20-30 times.",
          "request_timeout": "Sets the (10-120 seconds) timeout time for AI requests. Function: Controls the maximum time to wait for AI response, and may need to increase this value when generating longer text. Suggestion: If it is a short and quick response conversation, it can be set for about 10 seconds. If an AI error occurs, you can increase this value appropriately. If you want to generate long text with more than 1,000 words, it is recommended to set it for more than 60 seconds.",
          "filter_markdown": "Controls whether to filter Markdown format marks in AI responses. After turning on, the format symbols such as title and list will be removed.",
          "presence_penalty": "Control the tendency of the model to talk about new topics (-2 to 2). The higher the value, the more likely the model is to talk about new topics and avoid being around the same topic all the time. You can customize your favorite attribute values.",
          "frequency_penalty": "Controls the tendency of the model to repeat content (-2 to 2). The higher the value, the less likely the model is to repeat the same information, helping to generate more diverse answers. Style adjustments such as lively and cute style, that is, input a higher value.",
          "stop_sequences": "Set the stop mark for AI answers. Function: Accurately control the end position of AI answers. Select the appropriate stop mark according to the scene, use the period (.), use the line break (\\n) for multi-paragraph explanations, use the question mark (?) for Q&A dialogues, and use the semicolon (;) for status reports. Can be used in combination to control the length and format of the answer.",
          "tool_choice": "Control how the model uses tools. 'Automatic' let the model decide at its own discretion, 'disable' does not use tools at all, 'force' requires that the tools must be used. Please note that if you choose to disable the tool, you will not be able to use the control home device!"
        }
      },
      "history": {
        "title": "Entity historical data analysis configuration",
        "description": "Provide ** entity historical data analysis in scenarios where **Jinja2 template** (Home Assistant's template system) cannot be implemented to ensure that AI understands and analyzes your device data. For example: it can be used to automate the analysis of home security, personnel activity trajectory, daily life summary, UI text template introduction, etc.\n\n• Support **AI-assisted analysis**Historical data (let AI understand and analyze your device data)\n• Provide intelligent decision-making support for ** Device Management**\n• It is recommended to control the range of **1 day historical data for best results\n• **Special reminder**: For frequently updated environmental sensors such as temperature, humidity, light, etc., please avoid choosing to prevent AI overflow (can be set according to the default 10 minutes)",
        "data": {
          "history_entities": "Select entity",
          "history_days": "Get the (1-15 days) range of days in the repository",
          "history_interval": "Get the update time (minutes) of an entity in the repository"
        }
      }
    },
    "error": {
      "no_entities": "Please select at least one entity",
      "invalid_days": "The number of historical data days must be between 1-15 days"
    }
  },
  "selector": {
    "model_descriptions": {
      "options": {
        "GLM-4-Plus": "GLM-4-Plus - High-Smart Flagship, 128K/4K, 5 yuan/million tokens",
        "GLM-4-0520": "GLM-4-0520 - Stable version, 128K/4K, 100 yuan/million tokens",
        "GLM-4-Long": "GLM-4-Long - Extra long input, 1M/4K, 1 yuan/million tokens",
        "GLM-4-Air": "GLM-4-Air - High cost performance, 128K/16K, 0.5 yuan/million tokens",
        "GLM-4-Air-250414": "GLM-4-Air-250414 - High cost performance, 128K/16K, 0.5 yuan/million tokens",
        "GLM-4-AirX": "GLM-4-AirX - Speedy reasoning, 8K/4K, 10 yuan/million tokens",
        "GLM-4-Flash": "GLM-4-Flash - Free Universal, 128K/16K, Free",
        "glm-4-flash-250414": "GLM-4-Flash-250414 - Free universal, 128K/16K, free",
        "glm-4-flashx-250414": "GLM-4-FlashX-250414 - High-speed and low-price, 128K/4K, 0.1 yuan/million tokens",
        "glm-zero-preview": "glm-zero-preview - Early reasoning, 128K/16k, 0.1 yuan/million tokens",
        "GLM-Z1-Air": "GLM-Z1-Air - Lightweight reasoning, 128K/32K, 0.5 yuan/million tokens",
        "GLM-Z1-AirX": "GLM-Z1-AirX - Speedy reasoning, 32K/30K, 5 yuan/million tokens",
        "GLM-Z1-flash": "GLM-Z1-flash - Free reasoning, 128K/32K, free",
        "GLM-Z1-flashX-250414": "GLM-Z1-flashX-250414 - Low price reasoning, 128K/32K, 0.5 yuan/million tokens",
        "CharGLM-4": "CharGLM-4 - Anthropomorphic dialogue, 8K/4K, 1 yuan/million tokens",
        "GLM-4-AllTools": "GLM-4-AllTools - All-round tools, 128K/32K, 1 yuan/million token",
        "GLM-4-Assistant": "GLM-4-Assistant - All Intelligent, 128K/4K, 5 Yuan/Million Tokens",
        "GLM-4-CodeGeex-4": "GLM-4-CodeGeex - Code generation, 128K/32K, 0.1 yuan/million tokens"
      }
    },
    "stop_sequences": {
      "options": {
        "\\n": "Line breaks (\\n)",
        "。": "Full stop (.)",
        "！": "exclamation mark (!)",
        "？": "Question mark (?)",
        "；": "semicolon (;)",
        "：": "Colon (:)",
        ",": "English comma (,)",
        ".": "English full stop (.)"
      }
    },
    "tool_choice": {
      "options": {
        "auto": "automatic",
        "none": "Disabled",
        "force": "Mandatory"
      }
    },
    "filter_markdown": {
      "options": {
        "off": "closure",
        "on": "Open"
      }
    },
    "notify_service": {
      "options": {
        "persistent_notification": "Global notification (persistent_notification)"
      }
    }
  },
  "exceptions": {
    "invalid_config_entry": {
      "message": "The provided configuration entry is invalid. What you get is {config_entry}"
    }
  }
}